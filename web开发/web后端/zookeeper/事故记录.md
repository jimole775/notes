# 链接异常
- **事件描述**：
1. 如果，zkServer 重启之后所有的数据都丢失了，Client仍然会无限的尝试重连 zkServer，导致所有之前建立的 session，以及在他之上的 zkClient 不可用。

2. 该情况很容易复现：（在测试集群中）停掉所有节点上 zookeeper 服务 => 删除所有节点上 snapshot 以及 transaction 日志 => 启动所有节点上 zookeeper 服务；经过数据的清理过程，重启之后的 zookeeper 服务会 **丢失** 所有会话信息，但之前已经建立 session 的客户端因保存有 session ID 以及 session 密码，会不断尝试向不同的 zookeeper 节点回复会话；

3. 除非重启客户端，令客户端重新建立会话，否则客户端会进入 “锲而不舍” 的会话回复悲剧之中。

- **应对**：
1. zookeeper 的 zxid 会由于状态的变更主键递增 1，为了保证事务的顺序一致性，zookeeper 采用了递增的事务 id 号（zxid）来标识事务。这在选举的时候启动至关重要。

2. 但是如果把 snapshot 和 transitionlog 删除掉之后重启 zookeeper，zkServer 的 zxid 编号会从 0 开始递增。

3. 但是客户端仍然使用自己申请到的 zxid 重连，服务端发现客户端的 id 比服务端大，所以拒绝服务。

4. 网上的说法都是遇到这种情况需要重启 zk 客户端。如果不想重启，就需要改 zk 库的逻辑，在重连达到一定次数之后重新建立链接。

# ZK 脑裂
- **事件描述**：
1. 多个服务向 zk 同一个节点注册，注册的升级为 master 节点，其他的为 follower

2. 但是事故发生时，zk 服务不可用，master 节点没有感知到 expired 事件，因此认为自己仍是 master

3. 有一个 follower 服务感知到了 master 节点被删除的事件，把自己提升为 master。从此，集群有了两个master，因此导致整个集群的瘫痪。

# zk hang
- **事件描述**：
1. zk客户端和服务端网络不通畅的时候，服务端发出的 expired 事件并不能及时通知到客户端，客户端如果不能及时对 connecting 状态做出反应，仍然向 server 拉节点，如果用同步 API，就会造成 hang，如果用异步 API，operation_timeout 的通知也会过很久（C客户端上拉取节点超时的时间是三分之二的zktimeout时间）才返回。

# zk 雪崩
1. zk客户端的逻辑是：重连之后会对所有节点重新 watch，如果 zk 不可用导致所有的 zk 链接 expire，那么会导致所有的节点 server watch 节点，**惊群效应**会导致 zk 压力过大 => 服务处理延迟过大 => 导致 client 认为客户端连接失败 => zk客户端重连 => 连接失败 => 然后就会一直重连。无限循环。


