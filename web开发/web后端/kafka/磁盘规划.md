## 需求
我举一个简单的例子来说明该如何思考这个问题。假设你所在公司有一个业务需要每天向 Kafaka 集群发送 1 亿条信息，每条信息保存两份以上防止丢失，另外消息默认保存两周时间。

## 方案
我们来计算一下：每天 1 亿条 1KB 大小的消息，保存两份且存留两周的时间，那么总的空间大小就等于 1 亿 * 1KB * 2 / 1000 / 1000 = 200GB

一半情况下 Kafka 集群除了消息数据还有其他类型的数据，比如索引数据等，故我们再为这些数据预留出 10% 的磁盘空间，因此总的存储容量就是 220GB

既然要保存两周，那么整体容量即为 220GB * 14，大约 3TB 左右。Kafka 支持数据的压缩，假设压缩比是 0.75，那么最后你需要规划的存储空间就是 0.75 * 3 = 2.25TB
